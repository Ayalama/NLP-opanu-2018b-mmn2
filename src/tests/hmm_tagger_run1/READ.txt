test params:
############## train ###########
--model=bi-gram
--train_file=C:\\Users\\aymann\\PycharmProjects\\maman_12_NLP\\datasets\\heb-pos.train
--smoothing=n

############## decode ###########
--model=bi-gram
--test_file=C:\Users\aymann\PycharmProjects\maman_12_NLP\datasets\heb-pos.test
--param_file1=C:\Users\aymann\PycharmProjects\maman_12_NLP\tests\hmm_tagger_run1\hmm_tagger.lex
--param_file2=C:\Users\aymann\PycharmProjects\maman_12_NLP\tests\hmm_tagger_run1\hmm_tagger.gram

############## eval ###########
--model_tagged=C:\Users\aymann\PycharmProjects\maman_12_NLP\tests\hmm_tagger_run1\hmm_tagger.tagged
--gold_file=C:\Users\aymann\PycharmProjects\maman_12_NLP\datasets\heb-pos.gold
--model=bi-gram
--smoothing=n

############## Additional info ###########
* run without log prob transformation
* in this run, viterbi values calculated for each state
* unknown transition or unknown stat-word pairs are valued 0: p(w_i|s_i)=0 or p(s_i|s_i-1)=0 therefor p(w_i|s_i)=0*p(s_i|s_i-1)=0
* if all possible states are with value 0 for step (p(w_i|s_i)=0 or p(s_i|s_i-1)=0 for each state) than maxarg will be selected randomly

